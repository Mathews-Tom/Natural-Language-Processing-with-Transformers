{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER and Sentiment\n",
    "\n",
    "In this section we will work through applying basic sentiment analysis to our data using a pre-built *distilBERT* model from the **Flair** library. We will then use our organization labels captured through NER in the previous section to create a list of organizations with the highest and lowest average sentiment scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import flair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize the English sentiment model `en-sentiment`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-10 19:40:47,585 loading file /Users/druk/.flair/models/sentiment-en-mix-distillbert_4.pt\n"
     ]
    }
   ],
   "source": [
    "model = flair.models.TextClassifier.load('en-sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each sample there are a few steps we need to take to create the sentiment score. We need to tokenize the input text, make a prediction, extract the direction (*positive* or *negative*) and confidence (a score from 0 to 1). If this is new to you, we cover the Flair sentiment model in more depth in **TK insert link**.\n",
    "\n",
    "The following function carries out each of these steps for a single extract:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text):\n",
    "    # tokenize input text\n",
    "    sentence = flair.data.Sentence(text)\n",
    "    # make sentiment prediction\n",
    "    model.predict(sentence)\n",
    "    # extract sentiment direction and confidence (label and score) object\n",
    "    sentiment = sentence.labels[0]\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to load our previously processed dataframe (which includes the *organizations* column) and `apply` the `get_sentiment` function to the *selftext* column. These sentiment scores will then be stored in a new *sentiment* column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_utc</th>\n",
       "      <th>downs</th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>ups</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>organizations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.614290e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>t3_lshtjn</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Bloomberg article: [https://www.bloomberg.com/...</td>\n",
       "      <td>investing</td>\n",
       "      <td>Fed Views Rising Yields as Bullish Sign Reflec...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>['Fed', 'St. Louis Fed', 'Bostic', 'Treasury',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.614286e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>t3_lsgahw</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Given the recent downturn in stocks especially...</td>\n",
       "      <td>investing</td>\n",
       "      <td>ARK ETFs implosion risk ------------------------</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>['The Bear Cave](https://thebearcave.substack....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.614283e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>t3_lsf8td</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[https://twitter.com/desogames/status/13649710...</td>\n",
       "      <td>investing</td>\n",
       "      <td>The Counter-Party Risk Bubble</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>['OWN', 'ITM', 'REALLY', 'Collateral']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.614282e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>t3_lsf3nh</td>\n",
       "      <td>6.0</td>\n",
       "      <td>When you think of futures, what comes to your ...</td>\n",
       "      <td>investing</td>\n",
       "      <td>Futures were made for days like these</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.62</td>\n",
       "      <td>['the NQ on Feb 22', 'the new micro futures', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.614278e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>t3_lsdcib</td>\n",
       "      <td>3.0</td>\n",
       "      <td>I've been on this sub for quite some time and ...</td>\n",
       "      <td>investing</td>\n",
       "      <td>Let's talk about liquidity premiums</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    created_utc  downs         id  score  \\\n",
       "0  1.614290e+09    0.0  t3_lshtjn   10.0   \n",
       "1  1.614286e+09    0.0  t3_lsgahw   56.0   \n",
       "2  1.614283e+09    0.0  t3_lsf8td    1.0   \n",
       "3  1.614282e+09    0.0  t3_lsf3nh    6.0   \n",
       "4  1.614278e+09    0.0  t3_lsdcib    3.0   \n",
       "\n",
       "                                            selftext  subreddit  \\\n",
       "0  Bloomberg article: [https://www.bloomberg.com/...  investing   \n",
       "1  Given the recent downturn in stocks especially...  investing   \n",
       "2  [https://twitter.com/desogames/status/13649710...  investing   \n",
       "3  When you think of futures, what comes to your ...  investing   \n",
       "4  I've been on this sub for quite some time and ...  investing   \n",
       "\n",
       "                                               title   ups  upvote_ratio  \\\n",
       "0  Fed Views Rising Yields as Bullish Sign Reflec...  10.0          0.86   \n",
       "1   ARK ETFs implosion risk ------------------------  56.0          0.83   \n",
       "2                      The Counter-Party Risk Bubble   1.0          0.53   \n",
       "3              Futures were made for days like these   6.0          0.62   \n",
       "4                Let's talk about liquidity premiums   3.0          0.67   \n",
       "\n",
       "                                       organizations  \n",
       "0  ['Fed', 'St. Louis Fed', 'Bostic', 'Treasury',...  \n",
       "1  ['The Bear Cave](https://thebearcave.substack....  \n",
       "2             ['OWN', 'ITM', 'REALLY', 'Collateral']  \n",
       "3  ['the NQ on Feb 22', 'the new micro futures', ...  \n",
       "4                                                 []  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_csv('./data/processed/reddit_investing_ner.csv', sep='|')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_utc</th>\n",
       "      <th>downs</th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>ups</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>organizations</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.614290e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>t3_lshtjn</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Bloomberg article: [https://www.bloomberg.com/...</td>\n",
       "      <td>investing</td>\n",
       "      <td>Fed Views Rising Yields as Bullish Sign Reflec...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>['Fed', 'St. Louis Fed', 'Bostic', 'Treasury',...</td>\n",
       "      <td>Sentence: \"Bloomberg article : [ https :// www...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.614286e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>t3_lsgahw</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Given the recent downturn in stocks especially...</td>\n",
       "      <td>investing</td>\n",
       "      <td>ARK ETFs implosion risk ------------------------</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>['The Bear Cave](https://thebearcave.substack....</td>\n",
       "      <td>Sentence: \"Given the recent downturn in stocks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.614283e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>t3_lsf8td</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[https://twitter.com/desogames/status/13649710...</td>\n",
       "      <td>investing</td>\n",
       "      <td>The Counter-Party Risk Bubble</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>['OWN', 'ITM', 'REALLY', 'Collateral']</td>\n",
       "      <td>Sentence: \"[ https :// twitter.com / desogames...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.614282e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>t3_lsf3nh</td>\n",
       "      <td>6.0</td>\n",
       "      <td>When you think of futures, what comes to your ...</td>\n",
       "      <td>investing</td>\n",
       "      <td>Futures were made for days like these</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.62</td>\n",
       "      <td>['the NQ on Feb 22', 'the new micro futures', ...</td>\n",
       "      <td>Sentence: \"When you think of futures , what co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.614278e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>t3_lsdcib</td>\n",
       "      <td>3.0</td>\n",
       "      <td>I've been on this sub for quite some time and ...</td>\n",
       "      <td>investing</td>\n",
       "      <td>Let's talk about liquidity premiums</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>[]</td>\n",
       "      <td>Sentence: \"I 've been on this sub for quite so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    created_utc  downs         id  score  \\\n",
       "0  1.614290e+09    0.0  t3_lshtjn   10.0   \n",
       "1  1.614286e+09    0.0  t3_lsgahw   56.0   \n",
       "2  1.614283e+09    0.0  t3_lsf8td    1.0   \n",
       "3  1.614282e+09    0.0  t3_lsf3nh    6.0   \n",
       "4  1.614278e+09    0.0  t3_lsdcib    3.0   \n",
       "\n",
       "                                            selftext  subreddit  \\\n",
       "0  Bloomberg article: [https://www.bloomberg.com/...  investing   \n",
       "1  Given the recent downturn in stocks especially...  investing   \n",
       "2  [https://twitter.com/desogames/status/13649710...  investing   \n",
       "3  When you think of futures, what comes to your ...  investing   \n",
       "4  I've been on this sub for quite some time and ...  investing   \n",
       "\n",
       "                                               title   ups  upvote_ratio  \\\n",
       "0  Fed Views Rising Yields as Bullish Sign Reflec...  10.0          0.86   \n",
       "1   ARK ETFs implosion risk ------------------------  56.0          0.83   \n",
       "2                      The Counter-Party Risk Bubble   1.0          0.53   \n",
       "3              Futures were made for days like these   6.0          0.62   \n",
       "4                Let's talk about liquidity premiums   3.0          0.67   \n",
       "\n",
       "                                       organizations  \\\n",
       "0  ['Fed', 'St. Louis Fed', 'Bostic', 'Treasury',...   \n",
       "1  ['The Bear Cave](https://thebearcave.substack....   \n",
       "2             ['OWN', 'ITM', 'REALLY', 'Collateral']   \n",
       "3  ['the NQ on Feb 22', 'the new micro futures', ...   \n",
       "4                                                 []   \n",
       "\n",
       "                                           sentiment  \n",
       "0  Sentence: \"Bloomberg article : [ https :// www...  \n",
       "1  Sentence: \"Given the recent downturn in stocks...  \n",
       "2  Sentence: \"[ https :// twitter.com / desogames...  \n",
       "3  Sentence: \"When you think of futures , what co...  \n",
       "4  Sentence: \"I 've been on this sub for quite so...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get sentiment\n",
    "df['sentiment'] = df['selftext'].apply(get_sentiment)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to extract each of the organizations alongside it's sentiment score. We will then loop through each, tallying up a total sentiment score and count.\n",
    "\n",
    "Before we do that, we need to convert each value in the *organizations* column to a list (they are currently strings because we cannot save Python lists to file within Pandas dataframes, they are automatically converted to strings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "df['organizations'] = df['organizations'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize sentiment dictionary\n",
    "sentiment = {}\n",
    "\n",
    "# loop through dataframe and extract org labels and sentiment scores into sentiment dictionary\n",
    "for i, row in df.iterrows():\n",
    "    # extract sentiment direction and score\n",
    "    direction = row['sentiment'].value\n",
    "    score = row['sentiment'].score\n",
    "    # loop through each label in organizations column\n",
    "    for org in row['organizations']:\n",
    "        # check if org label exists in sentiment dictionary already\n",
    "        if org not in sentiment.keys():\n",
    "            # if it doesn't, initialize new entry in dictionary\n",
    "            sentiment[org] = {'POSITIVE': [], 'NEGATIVE': []}\n",
    "        # append positive/negative score to respective dictionary entry\n",
    "        sentiment[org][direction].append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'POSITIVE': [0.99809330701828, 0.7470293641090393, 0.999733030796051],\n",
       " 'NEGATIVE': [0.9974728226661682,\n",
       "  0.6304867267608643,\n",
       "  0.6143212914466858,\n",
       "  0.994274914264679,\n",
       "  0.9999703168869019,\n",
       "  0.9982093572616577,\n",
       "  0.9989243149757385,\n",
       "  0.9981945157051086,\n",
       "  0.9999686479568481]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment['ARK']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can loop through each organization entry in the sentiment dictionary and calculate an average positive, and average negative score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize sentiment list\n",
    "avg_sentiment = []\n",
    "\n",
    "# loop through each organization\n",
    "for org in sentiment.keys():\n",
    "    # get number of positive and negative ratings\n",
    "    freq = len(sentiment[org]['POSITIVE']) + len(sentiment[org]['NEGATIVE'])\n",
    "    for direction in ['POSITIVE', 'NEGATIVE']:\n",
    "        # assign to variable for cleaner code\n",
    "        score = sentiment[org][direction]\n",
    "        # if there are no entries, set to 0\n",
    "        if len(score) == 0:\n",
    "            sentiment[org][direction] = 0.0\n",
    "        else:\n",
    "            # otherwise calculate total\n",
    "            sentiment[org][direction] = sum(score)\n",
    "    # now calculate total amount\n",
    "    total = sentiment[org]['POSITIVE'] - sentiment[org]['NEGATIVE']\n",
    "    # and the average score\n",
    "    avg = total/freq\n",
    "    # add to sentiment list\n",
    "    avg_sentiment.append({\n",
    "        'entity': org,\n",
    "        'positive': sentiment[org]['POSITIVE'],\n",
    "        'negative': sentiment[org]['NEGATIVE'],\n",
    "        'frequency': freq,\n",
    "        'score': avg\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>frequency</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fed</td>\n",
       "      <td>2.326648</td>\n",
       "      <td>10.933105</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.614747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>St. Louis Fed</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.991645</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.991645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bostic</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.991645</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.991645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Treasury</td>\n",
       "      <td>0.610765</td>\n",
       "      <td>3.990731</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.675993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the Atlanta Fed’s</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.991645</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.991645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              entity  positive   negative  frequency     score\n",
       "0                Fed  2.326648  10.933105         14 -0.614747\n",
       "1      St. Louis Fed  0.000000   0.991645          1 -0.991645\n",
       "2             Bostic  0.000000   0.991645          1 -0.991645\n",
       "3           Treasury  0.610765   3.990731          5 -0.675993\n",
       "4  the Atlanta Fed’s  0.000000   0.991645          1 -0.991645"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df = pd.DataFrame(avg_sentiment)\n",
    "sentiment_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Immediately we can see we have a lot of entities which have appeared once in our dataset, and because of this their score will be pushed to one extreme or the other. We can filter out anything with less than or equal to a frequency of `3` to remove many of these instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>frequency</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fed</td>\n",
       "      <td>2.326648</td>\n",
       "      <td>10.933105</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.614747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Treasury</td>\n",
       "      <td>0.610765</td>\n",
       "      <td>3.990731</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.675993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ARK</td>\n",
       "      <td>2.744856</td>\n",
       "      <td>8.231823</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.457247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ITM</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.790710</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.947677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>eBay</td>\n",
       "      <td>1.879811</td>\n",
       "      <td>2.979899</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.220018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>Tilray</td>\n",
       "      <td>0.944136</td>\n",
       "      <td>4.664320</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.620031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553</th>\n",
       "      <td>PLTR</td>\n",
       "      <td>1.624318</td>\n",
       "      <td>1.911521</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.071801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>LMND</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.746245</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.949249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>Sony</td>\n",
       "      <td>4.888053</td>\n",
       "      <td>1.970413</td>\n",
       "      <td>7</td>\n",
       "      <td>0.416806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>SI</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.981616</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.995404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        entity  positive   negative  frequency     score\n",
       "0          Fed  2.326648  10.933105         14 -0.614747\n",
       "3     Treasury  0.610765   3.990731          5 -0.675993\n",
       "7          ARK  2.744856   8.231823         12 -0.457247\n",
       "9          ITM  0.000000   3.790710          4 -0.947677\n",
       "16        eBay  1.879811   2.979899          5 -0.220018\n",
       "...        ...       ...        ...        ...       ...\n",
       "1520    Tilray  0.944136   4.664320          6 -0.620031\n",
       "1553      PLTR  1.624318   1.911521          4 -0.071801\n",
       "1624      LMND  0.000000   4.746245          5 -0.949249\n",
       "2119      Sony  4.888053   1.970413          7  0.416806\n",
       "2644        SI  0.000000   3.981616          4 -0.995404\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df = sentiment_df[sentiment_df['frequency'] > 3]\n",
    "sentiment_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have some more relevant information. We can see a few items that we can remove through the `BLACKLIST` covered in earlier sections such as *Fed* and *Treasury*, but nonetheless this list is looking much better than before. We can apply `sort` to search for the entities with the highest overall score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>frequency</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>IBM</td>\n",
       "      <td>2.965104</td>\n",
       "      <td>0.883971</td>\n",
       "      <td>4</td>\n",
       "      <td>0.520283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>TAM</td>\n",
       "      <td>6.161803</td>\n",
       "      <td>1.880312</td>\n",
       "      <td>9</td>\n",
       "      <td>0.475721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>Yahoo Finance</td>\n",
       "      <td>2.310291</td>\n",
       "      <td>0.624828</td>\n",
       "      <td>4</td>\n",
       "      <td>0.421366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>Sony</td>\n",
       "      <td>4.888053</td>\n",
       "      <td>1.970413</td>\n",
       "      <td>7</td>\n",
       "      <td>0.416806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>Intel</td>\n",
       "      <td>4.226028</td>\n",
       "      <td>1.953940</td>\n",
       "      <td>7</td>\n",
       "      <td>0.324584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>Company</td>\n",
       "      <td>7.915097</td>\n",
       "      <td>4.899027</td>\n",
       "      <td>14</td>\n",
       "      <td>0.215434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>ER</td>\n",
       "      <td>2.690315</td>\n",
       "      <td>1.999680</td>\n",
       "      <td>5</td>\n",
       "      <td>0.138127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>YouTube</td>\n",
       "      <td>2.936317</td>\n",
       "      <td>2.180855</td>\n",
       "      <td>6</td>\n",
       "      <td>0.125910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Value</td>\n",
       "      <td>1.968677</td>\n",
       "      <td>1.735053</td>\n",
       "      <td>4</td>\n",
       "      <td>0.058406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>QQQ</td>\n",
       "      <td>2.730508</td>\n",
       "      <td>2.435801</td>\n",
       "      <td>6</td>\n",
       "      <td>0.049118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             entity  positive  negative  frequency     score\n",
       "1403            IBM  2.965104  0.883971          4  0.520283\n",
       "345             TAM  6.161803  1.880312          9  0.475721\n",
       "1495  Yahoo Finance  2.310291  0.624828          4  0.421366\n",
       "2119           Sony  4.888053  1.970413          7  0.416806\n",
       "504           Intel  4.226028  1.953940          7  0.324584\n",
       "481         Company  7.915097  4.899027         14  0.215434\n",
       "196              ER  2.690315  1.999680          5  0.138127\n",
       "353         YouTube  2.936317  2.180855          6  0.125910\n",
       "200           Value  1.968677  1.735053          4  0.058406\n",
       "100             QQQ  2.730508  2.435801          6  0.049118"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df.sort_values('score', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very quickly we've got our results that we have pulled together using simple, ready-to-use models, and **zero** text preprocessing. With further fine-tuning, and process development, these already good results can become great. Which we will cover soon."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "1391c78cdb2b882534495952f3f111444461f5e64b567be19ee9da577c36e6be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
